{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    totalUsers  totalPlays     avgPlays\n",
      "name                                                   \n",
      "Britney Spears             522     2393140  4584.559387\n",
      "Depeche Mode               282     1301308  4614.567376\n",
      "Lady Gaga                  611     1291387  2113.563011\n",
      "Christina Aguilera         407     1058405  2600.503686\n",
      "Paramore                   399      963449  2414.659148\n",
      "...                        ...         ...          ...\n",
      "Morris                       1           1     1.000000\n",
      "Eddie Kendricks              1           1     1.000000\n",
      "Excess Pressure              1           1     1.000000\n",
      "My Mine                      1           1     1.000000\n",
      "A.M. Architect               1           1     1.000000\n",
      "\n",
      "[17632 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "plays = pd.read_csv('data_lightfm/user_artists.dat', sep='\\t')\n",
    "artists = pd.read_csv('data_lightfm/artists.dat', sep='\\t', usecols=['id','name'])\n",
    "\n",
    "# Merge artist and user pref data\n",
    "ap = pd.merge(artists, plays, how=\"inner\", left_on=\"id\", right_on=\"artistID\")\n",
    "ap = ap.rename(columns={\"weight\": \"playCount\"})\n",
    "\n",
    "# Group artist by name\n",
    "artist_rank = ap.groupby(['name']) \\\n",
    "    .agg({'userID' : 'count', 'playCount' : 'sum'}) \\\n",
    "    .rename(columns={\"userID\" : 'totalUsers', \"playCount\" : \"totalPlays\"}) \\\n",
    "    .sort_values(['totalPlays'], ascending=False)\n",
    "\n",
    "artist_rank['avgPlays'] = artist_rank['totalPlays'] / artist_rank['totalUsers']\n",
    "print(artist_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparsity: 0.28\n"
     ]
    }
   ],
   "source": [
    "ap = ap.join(artist_rank, on=\"name\", how=\"inner\") \\\n",
    "    .sort_values(['playCount'], ascending=False)\n",
    "\n",
    "# Preprocessing\n",
    "pc = ap.playCount\n",
    "play_count_scaled = (pc - pc.min()) / (pc.max() - pc.min())\n",
    "ap = ap.assign(playCountScaled=play_count_scaled)\n",
    "#print(ap)\n",
    "\n",
    "# Build a user-artist rating matrix \n",
    "ratings_df = ap.pivot(index='userID', columns='artistID', values='playCountScaled')\n",
    "ratings = ratings_df.fillna(0).values\n",
    "\n",
    "# Show sparsity\n",
    "sparsity = float(len(ratings.nonzero()[0])) / (ratings.shape[0] * ratings.shape[1]) * 100\n",
    "print(\"sparsity: %.2f\" % sparsity)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating matrix shape (1892, 17632)\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Build a sparse matrix\n",
    "X = csr_matrix(ratings)\n",
    "\n",
    "n_users, n_items = ratings_df.shape\n",
    "print(\"rating matrix shape\", ratings_df.shape)\n",
    "\n",
    "user_ids = ratings_df.index.values\n",
    "artist_names = ap.sort_values(\"artistID\")[\"name\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import auc_score, precision_at_k, recall_at_k\n",
    "from lightfm.cross_validation import random_train_test_split\n",
    "from lightfm.data import Dataset\n",
    "\n",
    "# Build data references + train test\n",
    "Xcoo = X.tocoo()\n",
    "data = Dataset()\n",
    "data.fit(np.arange(n_users), np.arange(n_items))\n",
    "interactions, weights = data.build_interactions(zip(Xcoo.row, Xcoo.col, Xcoo.data)) \n",
    "train, test = random_train_test_split(interactions)\n",
    "\n",
    "# Ignore that (weight seems to be ignored...)\n",
    "#train = train_.tocsr()\n",
    "#test = test_.tocsr()\n",
    "#train[train==1] = X[train==1]\n",
    "#test[test==1] = X[test==1]\n",
    "\n",
    "# To be completed..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x7fb5712f2460>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train\n",
    "model = LightFM(learning_rate=0.05, loss='warp')\n",
    "model.fit(train, epochs=10, num_threads=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: train 0.37, test 0.13.\n",
      "AUC: train 0.97, test 0.86.\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "train_precision = precision_at_k(model, train, k=10).mean()\n",
    "test_precision = precision_at_k(model, test, k=10, train_interactions=train).mean()\n",
    "\n",
    "train_auc = auc_score(model, train).mean()\n",
    "test_auc = auc_score(model, test, train_interactions=train).mean()\n",
    "\n",
    "print('Precision: train %.2f, test %.2f.' % (train_precision, test_precision))\n",
    "print('AUC: train %.2f, test %.2f.' % (train_auc, test_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Radiohead' 'The Beatles' 'Depeche Mode' ... 'Hamza El Din' 'Soapkills'\n",
      " 'Oriental Breakbeats']\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "scores = model.predict(0, np.arange(n_items))\n",
    "top_items = artist_names[np.argsort(-scores)]\n",
    "print(top_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<lightfm.lightfm.LightFM object at 0x7fb5712f2460>\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0.20079407, 0.06787814), (0.88763523, 0.8087688)], [(0.34949705, 0.115446284), (0.84134626, 0.7731286)], [(0.37930122, 0.12768574), (0.96699524, 0.85800034)], [(0.35272634, 0.1252806), (0.88751566, 0.8173013)]]\n"
     ]
    }
   ],
   "source": [
    "les_valeur = []\n",
    "for i in [\"logistic\", \"bpr\", \"warp\", \"warp-kos\"]:\n",
    "    \n",
    "\n",
    "    model_for = LightFM(learning_rate=0.05, loss=i)\n",
    "    model_for.fit(train, epochs=10, num_threads=2)\n",
    "    \n",
    "    train_precision_1 = precision_at_k(model_for, train, k=10).mean()\n",
    "    \n",
    "    test_precision_1 = precision_at_k(model_for, test, k=10, train_interactions=train).mean()\n",
    "    \n",
    "    train_auc_1 = auc_score(model_for, train).mean()\n",
    "\n",
    "    test_auc_1 = auc_score(model_for, test, train_interactions=train).mean()\n",
    "    les_valeur.append([(train_precision_1, test_precision_1),(train_auc_1, test_auc_1) ])\n",
    "    df = pd.DataFrame(columns=[\"loss\", \"warp-kos\", \"bpr\", \"logistic\"], index=['train_precision','test_precision', 'train_auc','test_auc'])\n",
    "    df.append(index['train_precision']=)\n",
    "print(les_valeur)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                loss warp-kos  bpr logistic\n",
      "train_precision  NaN      NaN  NaN      NaN\n",
      "test_precision   NaN      NaN  NaN      NaN\n",
      "train_auc        NaN      NaN  NaN      NaN\n",
      "test_auc         NaN      NaN  NaN      NaN\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(n_components=100, n_iter=7, random_state=42)\n",
    "svd.fit(train)\n",
    "svd_precision = auc_score(model_for, train).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8897363"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=[\"loss\", \"warp-kos\", \"bpr\", \"logistic\"], index=['train_precision','test_precision', 'train_auc','test_auc'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
